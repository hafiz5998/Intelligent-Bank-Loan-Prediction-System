{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\anaconda\\lib\\site-packages\\tqdm\\std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import silhouette_score\n",
    "from boruta import BorutaPy\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "tqdm.pandas(tqdm_notebook)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler  # For scaling dataset\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, AffinityPropagation \n",
    "\n",
    "from apyori import apriori\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split functionn\n",
    "from IPython.display import Image  \n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.datasets import make_blobs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File Bank_CS.csv does not exist: 'Bank_CS.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-7af59b4a7eb0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Bank_CS.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Public\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File Bank_CS.csv does not exist: 'Bank_CS.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Bank_CS.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['Unnamed: 0']\n",
    "del df['Unnamed: 0.1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()\n",
    "#df1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nearest\n",
    "df1 = df.copy()\n",
    "df1['Years_to_Financial_Freedom'] = df1['Years_to_Financial_Freedom'].fillna(method='ffill')\n",
    "df1['Number_of_Credit_Card_Facility'] = df1['Number_of_Credit_Card_Facility'].fillna(method='ffill')\n",
    "df1['Number_of_Bank_Products'] = df1['Number_of_Bank_Products'].fillna(method='ffill')\n",
    "    \n",
    "df1['Property_Type'] = df1['Property_Type'].fillna(method='ffill')\n",
    "df1['Years_for_Property_to_Completion'] = df1['Years_for_Property_to_Completion'].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean\n",
    "df1['Loan_Amount'] = df1['Loan_Amount'].fillna(round(df1['Loan_Amount'].mean()))\n",
    "df1['Loan_Tenure_Year'] = df1['Loan_Tenure_Year'].fillna(round(df1['Loan_Tenure_Year'].mean()))\n",
    "df1['Number_of_Properties'] = df1['Number_of_Properties'].fillna(round(df1['Number_of_Properties'].mean()))\n",
    "\n",
    "df1['Number_of_Side_Income'] = df1['Number_of_Side_Income'].fillna(0)\n",
    "df1['Monthly_Salary'] = df1['Monthly_Salary'].fillna(round(df1['Monthly_Salary'].mean()))\n",
    "df1['Total_Sum_of_Loan'] = df1['Total_Sum_of_Loan'].fillna(round(df1['Total_Sum_of_Loan'].mean()))\n",
    "\n",
    "df1['Credit_Card_types'] = df1['Credit_Card_types'].fillna('Not Specified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"State\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['State']=df1['State'].replace('Johor B','Johor')\n",
    "df1['State']=df1['State'].replace('Penang','Pulau Pinang')\n",
    "df1['State']=df1['State'].replace('P.Pinang','Pulau Pinang')\n",
    "df1['State']=df1['State'].replace('Pulau Penang','Pulau Pinang')\n",
    "df1['State']=df1['State'].replace('K.L','Kuala Lumpur')\n",
    "df1['State']=df1['State'].replace('N.S','N.Sembilan')\n",
    "df1['State']=df1['State'].replace('SWK','Sarawak')\n",
    "df1['State']=df1['State'].replace('Trengganu','Terengganu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Total_Income_for_Join_Application']= np.where(df1['Total_Income_for_Join_Application'] < df1['Monthly_Salary'],  \n",
    "                                                   df1['Total_Income_for_Join_Application'].fillna(round(df1['Monthly_Salary'])),\n",
    "                                                   df1['Total_Income_for_Join_Application'].fillna(round(df1['Total_Income_for_Join_Application'].mean())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Credit_Card_types'].mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#df1.isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Number_of_Side_Income']==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1['Credit_Card_types'].unique()\n",
    "\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"Decision\"].value_counts().plot.bar()\n",
    "df1[\"Decision\"].value_counts()\n",
    "#75% Accepted from 2350 Applicant (1769)\n",
    "#581 rejected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.subplot(321)\n",
    "df1[\"Employment_Type\"].value_counts(normalize=True).plot.bar(figsize=(20,10), title= \"Employment\")\n",
    "plt.subplot(322)\n",
    "df1[\"Credit_Card_types\"].value_counts(normalize=True).plot.bar(figsize=(20,10), title= \"Credit_Card_types\")\n",
    "\n",
    "plt.subplot(325)\n",
    "df1[\"Property_Type\"].value_counts(normalize=True).plot.bar(figsize=(20,10), title= \"Property_Type\")\n",
    "plt.subplot(326)\n",
    "df1[\"State\"].value_counts(normalize=True).plot.bar(figsize=(20,10), title= \"State\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.subplot(121)\n",
    "sns.distplot(df1['Monthly_Salary']);\n",
    "plt.subplot(122) \n",
    "df1['Monthly_Salary'].plot.box(figsize=(16,5))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#graph for monthly_salary is normally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.boxplot(column = \"Monthly_Salary\",by= \"Employment_Type\") \n",
    "plt.suptitle(\"\")\n",
    "\n",
    "#There is employer that having very high income and appear to be outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.subplot(121)\n",
    "sns.distplot(df1['Loan_Amount']);\n",
    "plt.subplot(122) \n",
    "df1['Loan_Amount'].plot.box(figsize=(16,5))\n",
    "\n",
    "plt.show()\n",
    "#mean of loan amount applied is around 400000\n",
    "#no outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.subplot(121)\n",
    "sns.distplot(df1['Total_Income_for_Join_Application']);\n",
    "plt.subplot(122) \n",
    "df1['Total_Income_for_Join_Application'].plot.box(figsize=(16,10))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#great numbers of outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = df1.copy()\n",
    "corr1 = heatmap.corr()\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "sns.heatmap(corr1, vmax=.8, square=True, annot=True, fmt= '.2f', annot_kws={'size': 15}, cmap=\"BuPu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = df1.groupby('Employment_Type')['Decision'].value_counts()\n",
    "\n",
    "f2.unstack(0).plot.bar(figsize=(20,15))\n",
    "#plt.legend(loc='center left',bbox_to_anchor=(1.0,0.5))\n",
    "plt.title(\"Frequency of Credit Credit Card Type in Each State\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = df1.groupby('Credit_Card_Exceed_Months')['Decision'].value_counts()\n",
    "\n",
    "f2.unstack(0).plot.bar(figsize=(20,15))\n",
    "#plt.legend(loc='center left',bbox_to_anchor=(1.0,0.5))\n",
    "plt.title(\"Frequency of Credit Credit Card Type in Each State\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = df1.groupby('Credit_Card_types')['State'].value_counts()\n",
    "\n",
    "f2.unstack(0).plot.bar(figsize=(20,15))\n",
    "#plt.legend(loc='center left',bbox_to_anchor=(1.0,0.5))\n",
    "plt.title(\"Frequency of Credit Credit Card Type in Each State\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter1 = df1[df1[\"Decision\"] == 'Accept']\n",
    "filter1 = filter1.groupby([\"State\"], as_index=False).agg({\"Monthly_Salary\": \"mean\"})\n",
    "filter1 = filter1.rename(columns={\"Monthly_Salary\": \"Monthly_SalaryYes\"})\n",
    "\n",
    "filter2 = df1[df1[\"Decision\"] == 'Reject']\n",
    "filter2 = filter2.groupby([\"State\"], as_index=False).agg({\"Monthly_Salary\": \"mean\"})\n",
    "filter2 = filter2.rename(columns={\"Monthly_Salary\": \"Monthly_SalaryNo\"})\n",
    "\n",
    "filter9 = filter1.merge(filter2,on=\"State\",how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = df1[df1[\"Decision\"] == \"Accept\"]\n",
    "filtered= (filtered.groupby([\"State\"]).agg({\"Monthly_Salary\": \"mean\"}))\n",
    "f1 = filtered.values\n",
    "\n",
    "filteredN = df1[df1[\"Decision\"] == \"Reject\"]\n",
    "filteredN= (filtered.groupby([\"State\"]).agg({\"Monthly_Salary\": \"mean\"}))\n",
    "f2 = filtered.values\n",
    "\n",
    "labels = filter9[\"State\"]\n",
    "YES = filter9[\"Monthly_SalaryYes\"]\n",
    "NO = filter9[\"Monthly_SalaryNo\"]\n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,15))\n",
    "rects1 = ax.bar(x - width/2, YES, width, label='Accept')\n",
    "rects2 = ax.bar(x + width/2, NO, width, label='Reject')\n",
    "\n",
    "#ax.set_ylabel('Scores')\n",
    "#ax.set_title('Scores by group and gender')\n",
    "ax.set_xticks(x)\n",
    "\n",
    "ax.set_xticklabels(labels, rotation=90)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter1 = df1[df1[\"Decision\"] == 'Accept']\n",
    "filter1 = filter1.groupby([\"Property_Type\"], as_index=False).agg({\"Monthly_Salary\": \"mean\"})\n",
    "filter1 = filter1.rename(columns={\"Monthly_Salary\": \"Monthly_SalaryYes\"})\n",
    "\n",
    "filter2 = df1[df1[\"Decision\"] == 'Reject']\n",
    "filter2 = filter2.groupby([\"Property_Type\"], as_index=False).agg({\"Monthly_Salary\": \"mean\"})\n",
    "filter2 = filter2.rename(columns={\"Monthly_Salary\": \"Monthly_SalaryNo\"})\n",
    "\n",
    "filter9a = filter1.merge(filter2,on=\"Property_Type\",how='inner')\n",
    "filter9a\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = filter9a[\"Property_Type\"]\n",
    "PropertyYes = filter9a[\"Monthly_SalaryYes\"]\n",
    "PropertyNo = filter9a[\"Monthly_SalaryNo\"]\n",
    "\n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,15))\n",
    "rects1 = ax.bar(x - width/2, PropertyYes, width, label='Accept')\n",
    "rects2 = ax.bar(x + width/2, PropertyNo, width, label='Reject')\n",
    "\n",
    "#ax.set_ylabel('Scores')\n",
    "#ax.set_title('Scores by group and gender')\n",
    "ax.set_xticks(x)\n",
    "\n",
    "ax.set_xticklabels(labels, rotation=90)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count -> no of properties , \n",
    "\n",
    "f3 = df1.groupby('Number_of_Properties')['Decision'].value_counts()\n",
    "\n",
    "f3.unstack(0).plot.bar(figsize=(20,15))\n",
    "#plt.legend(loc='center left',bbox_to_anchor=(1.0,0.5))\n",
    "plt.title(\"Frequency of Credit Credit Card Type in Each State\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa1= df1[[\"Number_of_Properties\",\"Decision\",\"Credit_Card_types\",\"Employment_Type\"]]\n",
    "g1= (fa1[\"Decision\"]== 'Accept')\n",
    "g2=fa1[g1]\n",
    "\n",
    "g3=((g2[\"Credit_Card_types\"]=='platinum') \n",
    "    | (g2[\"Credit_Card_types\"]=='gold')\n",
    "    | (g2[\"Credit_Card_types\"]=='normal')\n",
    "    | (g2[\"Credit_Card_types\"]=='Not Specified'))\n",
    "\n",
    "g5=g2[g3]\n",
    "g5\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "ax = sns.countplot( x=\"Employment_Type\", hue = 'Credit_Card_types', data=g5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa1= df1[[\"Number_of_Properties\",\"Decision\",\"Credit_Card_types\",\"Employment_Type\"]]\n",
    "g1= (fa1[\"Decision\"]== 'Reject')\n",
    "g2=fa1[g1]\n",
    "\n",
    "g3=((g2[\"Credit_Card_types\"]=='platinum') \n",
    "    | (g2[\"Credit_Card_types\"]=='gold')\n",
    "    | (g2[\"Credit_Card_types\"]=='normal')\n",
    "    | (g2[\"Credit_Card_types\"]=='Not Specified'))\n",
    "\n",
    "g5=g2[g3]\n",
    "g5\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "ax = sns.countplot( x=\"Employment_Type\", hue = 'Credit_Card_types', data=g5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodependent= df1[[\"Number_of_Dependents\",\"Total_Sum_of_Loan\",\"Monthly_Salary\",\"Decision\"]]\n",
    "nodependent[\"Salary_Group\"] = pd.cut(nodependent[\"Monthly_Salary\"], bins = [3000,5000,7000,9000,11000,13000])\n",
    "\n",
    "a1= (nodependent[\"Decision\"]== 'Accept')\n",
    "a2=nodependent[a1]\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "ax = sns.countplot( x=\"Salary_Group\", hue = 'Number_of_Dependents', data=a2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1= (nodependent[\"Decision\"]== 'Reject')\n",
    "d2=nodependent[d1]\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "ax = sns.countplot( x=\"Salary_Group\", hue = 'Number_of_Dependents', data=d2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumofloan = df1[[\"Number_of_Dependents\",\"Total_Sum_of_Loan\",\"Monthly_Salary\",\"Decision\"]]\n",
    "\n",
    "sumofloan[\"Salary_Group\"] = pd.cut(sumofloan[\"Monthly_Salary\"], bins = [3000,5000,7000,9000,11000,13000])\n",
    "sumofloan[\"Sum_of_Loan_Group\"] = pd.cut(sumofloan[\"Total_Sum_of_Loan\"], bins = [400000,600000,800000,1000000,1200000,1500000])\n",
    "\n",
    "b1= (sumofloan[\"Decision\"]== 'Accept')\n",
    "b2=sumofloan[b1]\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "ax = sns.countplot( x=\"Salary_Group\", hue = 'Sum_of_Loan_Group', data=b2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1= (sumofloan[\"Decision\"]== 'Reject')\n",
    "c2=sumofloan[c1]\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "ax = sns.countplot( x=\"Salary_Group\", hue = 'Sum_of_Loan_Group', data=c2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2= df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Employment_Type'] = LabelEncoder().fit_transform(df2.Employment_Type)\n",
    "df2['More_Than_One_Products'] = LabelEncoder().fit_transform(df2.More_Than_One_Products)\n",
    "df2['Credit_Card_types'] = LabelEncoder().fit_transform(df2.Credit_Card_types)\n",
    "df2['Property_Type'] = LabelEncoder().fit_transform(df2.Property_Type)\n",
    "df2['State'] = LabelEncoder().fit_transform(df2.State)\n",
    "df2['Decision'] = LabelEncoder().fit_transform(df2.Decision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df2.Decision\n",
    "X = df2.drop(\"Decision\",1)\n",
    "colnames = X.columns\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranking(ranks, names, order=1):\n",
    "    minmax = MinMaxScaler()\n",
    "    ranks = minmax.fit_transform(order*np.array([ranks]).T).T[0]\n",
    "    ranks = map(lambda x: round(x,2), ranks)\n",
    "    return dict(zip(names, ranks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1, class_weight=\"balanced\", max_depth=5)\n",
    "feat_selector = BorutaPy(rf, n_estimators=\"auto\", random_state=1)\n",
    "feat_selector.fit(X.values, y.values.ravel())\n",
    "\n",
    "\n",
    "# sort the boruta score descending\n",
    "\n",
    "boruta_score = ranking(list(map(float, feat_selector.ranking_)), colnames, order=-1)\n",
    "boruta_score = pd.DataFrame(list(boruta_score.items()), columns=['Features', 'Score'])\n",
    "boruta_score = boruta_score.sort_values('Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('---------Top 10----------')\n",
    "display(boruta_score.head(10))\n",
    "\n",
    "print('---------Bottom 10----------')   \n",
    "boruta_score.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns_boruta_plot = sns.catplot(x=\"Score\", y=\"Features\", data = boruta_score[0:30], kind = \"bar\", \n",
    "               height=14, aspect=1.9, palette='coolwarm')\n",
    "plt.title(\"Boruta Top 20 Features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification model before SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr, Xts, ytr, yts = train_test_split(X,y.values.ravel(),test_size=0.3,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr=Xtr[['Loan_Amount','Monthly_Salary','Total_Sum_of_Loan','State','Credit_Card_types','Number_of_Credit_Card_Facility','Employment_Type','Credit_Card_Exceed_Months','Total_Income_for_Join_Application','Loan_Tenure_Year','Years_to_Financial_Freedom']]\n",
    "Xts=Xts[['Loan_Amount','Monthly_Salary','Total_Sum_of_Loan','State','Credit_Card_types','Number_of_Credit_Card_Facility','Employment_Type','Credit_Card_Exceed_Months','Total_Income_for_Join_Application','Loan_Tenure_Year','Years_to_Financial_Freedom']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(Xtr,ytr)\n",
    "\n",
    "y_pred = knn.predict(Xts)\n",
    "\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(knn.score(Xtr, ytr)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(knn.score(Xts, yts)))\n",
    "#knn.score(X_test,y_test)\n",
    "\n",
    "confusion_majority=confusion_matrix(yts, y_pred)\n",
    "\n",
    "print('Mjority classifier Confusion Matrix\\n', confusion_majority)\n",
    "\n",
    "print('**********************')\n",
    "print('Mjority TN= ', confusion_majority[0][0])\n",
    "print('Mjority FP=',  confusion_majority[0][1])\n",
    "print('Mjority FN= ', confusion_majority[1][0])\n",
    "print('Mjority TP= ', confusion_majority[1][1])\n",
    "print('**********************')\n",
    "\n",
    "print('Precision= {:.2f}'.format(precision_score(yts, y_pred)))\n",
    "print('Recall= {:.2f}'. format(recall_score(yts, y_pred)))\n",
    "print('F1= {:.2f}'. format(f1_score(yts, y_pred)))\n",
    "print('Accuracy= {:.2f}'. format(accuracy_score(yts, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier(criterion='entropy',max_depth=12)\n",
    "DT.fit(Xtr,ytr)\n",
    "y_pred=DT.predict(Xts)\n",
    "\n",
    "confusion_majority=confusion_matrix(yts, y_pred)\n",
    "\n",
    "print('Mjority classifier Confusion Matrix\\n', confusion_majority)\n",
    "\n",
    "print('**********************')\n",
    "print('Mjority TN= ', confusion_majority[0][0])\n",
    "print('Mjority FP=',  confusion_majority[0][1])\n",
    "print('Mjority FN= ', confusion_majority[1][0])\n",
    "print('Mjority TP= ', confusion_majority[1][1])\n",
    "print('**********************')\n",
    "\n",
    "print('Precision= {:.2f}'.format(precision_score(yts, y_pred)))\n",
    "print('Recall= {:.2f}'. format(recall_score(yts, y_pred)))\n",
    "print('F1= {:.2f}'. format(f1_score(yts, y_pred)))\n",
    "print('Accuracy= {:.2f}'. format(accuracy_score(yts, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier(criterion='entropy',max_depth=12)\n",
    "\n",
    "kf = KFold(n_splits=5,shuffle=True)\n",
    "kf.split(Xtr)\n",
    "\n",
    "accuracy_model = []\n",
    "i=0\n",
    "for train_index,test_index in kf.split(Xtr):\n",
    "    \n",
    "    Xtrain, Xtest = Xtr.iloc[train_index], Xtr.iloc[test_index]\n",
    "    ytrain, ytest = ytr[train_index], ytr[test_index]\n",
    "    DT.fit(Xtrain,ytrain)\n",
    "    accuracy_model.append(accuracy_score(ytest, DT.predict(Xtest), normalize=True)*100)\n",
    "    #print([i] \"of kfold\" + n_splits + accuracy_model[i])\n",
    "    print('\\n{} of kfold {}' .format(i+1,kf.n_splits))\n",
    "    print(accuracy_model[i])\n",
    "    i += 1\n",
    "\n",
    "    \n",
    "scores = pd.DataFrame(accuracy_model,columns=['Scores'])\n",
    " \n",
    "sns.set(style=\"white\", rc={\"lines.linewidth\": 3})\n",
    "sns.barplot(x=['Kfold 1','Kfold 2','Kfold 3','Kfold 4','Kfold 5'],y=\"Scores\",data=scores)\n",
    "plt.show()\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(max_depth = 10)\n",
    "forest.fit(Xtr,ytr)\n",
    "y_pred=forest.predict(Xts)\n",
    "confusion_majority=confusion_matrix(yts, y_pred)\n",
    "\n",
    "print('Mjority classifier Confusion Matrix\\n', confusion_majority)\n",
    "\n",
    "print('**********************')\n",
    "print('Mjority TN= ', confusion_majority[0][0])\n",
    "print('Mjority FP=',  confusion_majority[0][1])\n",
    "print('Mjority FN= ', confusion_majority[1][0])\n",
    "print('Mjority TP= ', confusion_majority[1][1])\n",
    "print('**********************')\n",
    "\n",
    "print('Precision= {:.2f}'.format(precision_score(yts, y_pred)))\n",
    "print('Recall= {:.2f}'. format(recall_score(yts, y_pred)))\n",
    "print('F1= {:.2f}'. format(f1_score(yts, y_pred)))\n",
    "print('Accuracy= {:.2f}'. format(accuracy_score(yts, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(max_depth = 10)\n",
    "\n",
    "kf = KFold(n_splits=5,shuffle=True)\n",
    "kf.split(Xtr)\n",
    "\n",
    "accuracy_model = []\n",
    "i=0\n",
    "for train_index,test_index in kf.split(Xtr):\n",
    "    \n",
    "    Xtrain, Xtest = Xtr.iloc[train_index], Xtr.iloc[test_index]\n",
    "    ytrain, ytest = ytr[train_index], ytr[test_index]\n",
    "    forest.fit(Xtrain,ytrain)\n",
    "    accuracy_model.append(accuracy_score(ytest, forest.predict(Xtest), normalize=True)*100)\n",
    "    #print([i] \"of kfold\" + n_splits + accuracy_model[i])\n",
    "    print('\\n{} of kfold {}' .format(i+1,kf.n_splits))\n",
    "    print(accuracy_model[i])\n",
    "    i += 1\n",
    "\n",
    "    \n",
    "scores = pd.DataFrame(accuracy_model,columns=['Scores'])\n",
    " \n",
    "sns.set(style=\"white\", rc={\"lines.linewidth\": 3})\n",
    "sns.barplot(x=['Kfold 1','Kfold 2','Kfold 3','Kfold 4','Kfold 5'],y=\"Scores\",data=scores)\n",
    "plt.show()\n",
    "sns.set()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb1=XGBClassifier(learning_rate =0.1, n_estimators=1000, max_depth=8, min_child_weight=6, gamma=0.1, subsample=0.9,\n",
    "                     colsample_bytree=0.95,reg_alpha=2, objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27)\n",
    "xgb1.fit(Xtr,ytr)\n",
    "y_pred=xgb1.predict(Xts)\n",
    "\n",
    "confusion_majority=confusion_matrix(yts, y_pred)\n",
    "\n",
    "print('Mjority classifier Confusion Matrix\\n', confusion_majority)\n",
    "\n",
    "print('**********************')\n",
    "print('Mjority TN= ', confusion_majority[0][0])\n",
    "print('Mjority FP=',  confusion_majority[0][1])\n",
    "print('Mjority FN= ', confusion_majority[1][0])\n",
    "print('Mjority TP= ', confusion_majority[1][1])\n",
    "print('**********************')\n",
    "\n",
    "print('Precision= {:.2f}'.format(precision_score(yts, y_pred)))\n",
    "print('Recall= {:.2f}'. format(recall_score(yts, y_pred)))\n",
    "print('F1= {:.2f}'. format(f1_score(yts, y_pred)))\n",
    "print('Accuracy= {:.2f}'. format(accuracy_score(yts, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb1=XGBClassifier(learning_rate =0.1, n_estimators=1000, max_depth=8, min_child_weight=6, gamma=0.1, subsample=0.9,\n",
    "                     colsample_bytree=0.95,reg_alpha=2, objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27)\n",
    "\n",
    "kf = KFold(n_splits=5,shuffle=True)\n",
    "kf.split(Xtr)\n",
    "\n",
    "accuracy_model = []\n",
    "i=0\n",
    "for train_index,test_index in kf.split(Xtr):\n",
    "    \n",
    "    Xtrain, Xtest = Xtr.iloc[train_index], Xtr.iloc[test_index]\n",
    "    ytrain, ytest = ytr[train_index], ytr[test_index]\n",
    "    xgb1.fit(Xtrain,ytrain)\n",
    "    accuracy_model.append(accuracy_score(ytest, xgb1.predict(Xtest), normalize=True)*100)\n",
    "    #print([i] \"of kfold\" + n_splits + accuracy_model[i])\n",
    "    print('\\n{} of kfold {}' .format(i+1,kf.n_splits))\n",
    "    print(accuracy_model[i])\n",
    "    i += 1\n",
    "\n",
    "    \n",
    "scores = pd.DataFrame(accuracy_model,columns=['Scores'])\n",
    " \n",
    "sns.set(style=\"white\", rc={\"lines.linewidth\": 3})\n",
    "sns.barplot(x=['Kfold 1','Kfold 2','Kfold 3','Kfold 4','Kfold 5'],y=\"Scores\",data=scores)\n",
    "plt.show()\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier(base_estimator=forest ,n_estimators=500, learning_rate=0.1, random_state=0)\n",
    "ada.fit(Xtr,ytr)\n",
    "y_pred=ada.predict(Xts)\n",
    "\n",
    "confusion_majority=confusion_matrix(yts, y_pred)\n",
    "\n",
    "print('Mjority classifier Confusion Matrix\\n', confusion_majority)\n",
    "\n",
    "print('**********************')\n",
    "print('Mjority TN= ', confusion_majority[0][0])\n",
    "print('Mjority FP=',  confusion_majority[0][1])\n",
    "print('Mjority FN= ', confusion_majority[1][0])\n",
    "print('Mjority TP= ', confusion_majority[1][1])\n",
    "print('**********************')\n",
    "\n",
    "print('Precision= {:.2f}'.format(precision_score(yts, y_pred)))\n",
    "print('Recall= {:.2f}'. format(recall_score(yts, y_pred)))\n",
    "print('F1= {:.2f}'. format(f1_score(yts, y_pred)))\n",
    "print('Accuracy= {:.2f}'. format(accuracy_score(yts, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier(base_estimator=forest ,n_estimators=500, learning_rate=0.1, random_state=0)\n",
    "\n",
    "kf = KFold(n_splits=5,shuffle=True)\n",
    "kf.split(Xtr)\n",
    "\n",
    "accuracy_model = []\n",
    "i=0\n",
    "for train_index,test_index in kf.split(Xtr):\n",
    "    \n",
    "    Xtrain, Xtest = Xtr.iloc[train_index], Xtr.iloc[test_index]\n",
    "    ytrain, ytest = ytr[train_index], ytr[test_index]\n",
    "    ada.fit(Xtrain,ytrain)\n",
    "    accuracy_model.append(accuracy_score(ytest, ada.predict(Xtest), normalize=True)*100)\n",
    "    #print([i] \"of kfold\" + n_splits + accuracy_model[i])\n",
    "    print('\\n{} of kfold {}' .format(i+1,kf.n_splits))\n",
    "    print(accuracy_model[i])\n",
    "    i += 1\n",
    "\n",
    "    \n",
    "scores = pd.DataFrame(accuracy_model,columns=['Scores'])\n",
    " \n",
    "sns.set(style=\"white\", rc={\"lines.linewidth\": 3})\n",
    "sns.barplot(x=['Kfold 1','Kfold 2','Kfold 3','Kfold 4','Kfold 5'],y=\"Scores\",data=scores)\n",
    "plt.show()\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os = SMOTE(random_state=10)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X,y.values.ravel(),test_size=0.3,random_state=10)\n",
    "columns = X.columns\n",
    "os_data_X, os_data_y=os.fit_sample(X,y)\n",
    "\n",
    "os_data_X = pd.DataFrame(data=os_data_X,columns=columns)\n",
    "os_data_y = pd.DataFrame(data=os_data_y,columns=['Decision'])\n",
    "\n",
    "print(\"length of oversampled data is\",len(os_data_X))\n",
    "print(\"Number of no subscription in oversampled data\",len(os_data_y[os_data_y['Decision']==0]))\n",
    "print(\"Number of subscription\",len(os_data_y[os_data_y['Decision']==1]))\n",
    "print(\"Proportion of no subscription data in oversampled data is\",len(os_data_y[os_data_y['Decision']==0])/len(os_data_X))\n",
    "print(\"Proportion of subscription data in oversampled data is\",len(os_data_y[os_data_y['Decision']==1])/len(os_data_X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df2[\"Decision\"].value_counts())\n",
    "\n",
    "plt.figure(1)\n",
    "plt.subplot(121)\n",
    "df2[\"Decision\"].value_counts().plot(kind=\"bar\",figsize=(16,5))\n",
    "plt.title(\"Class Distribution Before Smote\")\n",
    "\n",
    "plt.subplot(122) \n",
    "#print(os_data_y[\"Decision\"].value_counts())\n",
    "os_data_y[\"Decision\"].value_counts().plot(kind=\"bar\",figsize=(16,5))\n",
    "plt.title(\"Class Distribution After Smote\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(os_data_X,os_data_y.values.ravel(),test_size=0.3,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train[['Loan_Amount','Monthly_Salary','Total_Sum_of_Loan','State','Credit_Card_types','Number_of_Credit_Card_Facility','Employment_Type','Credit_Card_Exceed_Months','Total_Income_for_Join_Application','Loan_Tenure_Year','Years_to_Financial_Freedom']]\n",
    "X_test=X_test[['Loan_Amount','Monthly_Salary','Total_Sum_of_Loan','State','Credit_Card_types','Number_of_Credit_Card_Facility','Employment_Type','Credit_Card_Exceed_Months','Total_Income_for_Join_Application','Loan_Tenure_Year','Years_to_Financial_Freedom']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boruta After SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1, class_weight=\"balanced\", max_depth=5)\n",
    "feat_selector = BorutaPy(rf, n_estimators=\"auto\", random_state=1)\n",
    "feat_selector.fit(os_data_X.values, os_data_y.values.ravel())\n",
    "\n",
    "\n",
    "# sort the boruta score descending\n",
    "\n",
    "boruta_score = ranking(list(map(float, feat_selector.ranking_)), colnames, order=-1)\n",
    "boruta_score = pd.DataFrame(list(boruta_score.items()), columns=['Features', 'Score'])\n",
    "boruta_score = boruta_score.sort_values('Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('---------Top 10----------')\n",
    "display(boruta_score.head(10))\n",
    "\n",
    "print('---------Bottom 10----------')   \n",
    "boruta_score.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns_boruta_plot = sns.catplot(x=\"Score\", y=\"Features\", data = boruta_score[0:30], kind = \"bar\", \n",
    "               height=14, aspect=1.9, palette='coolwarm')\n",
    "plt.title(\"Boruta Top 20 Features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Model After Smote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(max_depth = 10)\n",
    "forest.fit(X_train,y_train)\n",
    "y_pred = forest.predict(X_test)\n",
    "#scores = cross_val_score(forest, X_train,y_train, cv=5)\n",
    "#forest.score(X_test, y_test)\n",
    " \n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(forest.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(forest.score(X_test, y_test)))\n",
    "#print(accuracy_score(y_train,scores))\n",
    "\n",
    "confusion_majority=confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Mjority classifier Confusion Matrix\\n', confusion_majority)\n",
    "\n",
    "print('**********************')\n",
    "print('Mjority TN= ', confusion_majority[0][0])\n",
    "print('Mjority FP=',  confusion_majority[0][1])\n",
    "print('Mjority FN= ', confusion_majority[1][0])\n",
    "print('Mjority TP= ', confusion_majority[1][1])\n",
    "print('**********************')\n",
    "\n",
    "print('Precision= {:.2f}'.format(precision_score(y_test, y_pred)))\n",
    "print('Recall= {:.2f}'. format(recall_score(y_test, y_pred)))\n",
    "print('F1= {:.2f}'. format(f1_score(y_test, y_pred)))\n",
    "print('Accuracy= {:.2f}'. format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF crossValidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(max_depth = 10)\n",
    "\n",
    "kf = KFold(n_splits=5,shuffle=True)\n",
    "kf.split(X_train)\n",
    "\n",
    "accuracy_model = []\n",
    "i=0\n",
    "for train_index,test_index in kf.split(X_train):\n",
    "    \n",
    "    Xtrain, Xtest = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    ytrain, ytest = y_train[train_index], y_train[test_index]\n",
    "    forest.fit(Xtrain,ytrain)\n",
    "    accuracy_model.append(accuracy_score(ytest, forest.predict(Xtest), normalize=True)*100)\n",
    "    #print([i] \"of kfold\" + n_splits + accuracy_model[i])\n",
    "    print('\\n{} of kfold {}' .format(i+1,kf.n_splits))\n",
    "    print(accuracy_model[i])\n",
    "    i += 1\n",
    "\n",
    "    \n",
    "scores = pd.DataFrame(accuracy_model,columns=['Scores'])\n",
    " \n",
    "sns.set(style=\"white\", rc={\"lines.linewidth\": 3})\n",
    "sns.barplot(x=['Kfold 1','Kfold 2','Kfold 3','Kfold 4','Kfold 5'],y=\"Scores\",data=scores)\n",
    "plt.show()\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_forest = forest.predict_proba(X_test)\n",
    "prob_forest = prob_forest[:,1]\n",
    "\n",
    "auc_forest = roc_auc_score(y_test,prob_forest)\n",
    "#print('AUC: %.2f'%auc_DT)\n",
    "fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_test, prob_forest) \n",
    "\n",
    "plt.plot(fpr_forest, tpr_forest, color='blue', label='RF') \n",
    "plt.plot([0, 1], [0, 1], color='green', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Adaboost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier(base_estimator=forest ,n_estimators=500, learning_rate=0.1, random_state=0)\n",
    "ada.fit(X_train,y_train)\n",
    "y_pred = ada.predict(X_test)\n",
    "ada.score(X_test, y_test)\n",
    "\n",
    "confusion_majority=confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Mjority classifier Confusion Matrix\\n', confusion_majority)\n",
    "\n",
    "print('**********************')\n",
    "print('Mjority TN= ', confusion_majority[0][0])\n",
    "print('Mjority FP=',  confusion_majority[0][1])\n",
    "print('Mjority FN= ', confusion_majority[1][0])\n",
    "print('Mjority TP= ', confusion_majority[1][1])\n",
    "print('**********************')\n",
    "\n",
    "print('Precision= {:.2f}'.format(precision_score(y_test, y_pred)))\n",
    "print('Recall= {:.2f}'. format(recall_score(y_test, y_pred)))\n",
    "print('F1= {:.2f}'. format(f1_score(y_test, y_pred)))\n",
    "print('Accuracy= {:.2f}'. format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost CrossValidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier(base_estimator=forest ,n_estimators=500, learning_rate=0.1, random_state=0)\n",
    "\n",
    "kf = KFold(n_splits=5,shuffle=True)\n",
    "kf.split(X_train)\n",
    "\n",
    "accuracy_model = []\n",
    "i=0\n",
    "for train_index,test_index in kf.split(X_train):\n",
    "    \n",
    "    Xtrain, Xtest = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    ytrain, ytest = y_train[train_index], y_train[test_index]\n",
    "    ada.fit(Xtrain,ytrain)\n",
    "    accuracy_model.append(accuracy_score(ytest, ada.predict(Xtest), normalize=True)*100)\n",
    "    #print([i] \"of kfold\" + n_splits + accuracy_model[i])\n",
    "    print('\\n{} of kfold {}' .format(i+1,kf.n_splits))\n",
    "    print(accuracy_model[i])\n",
    "    i += 1\n",
    "\n",
    "    \n",
    "scores = pd.DataFrame(accuracy_model,columns=['Scores'])\n",
    " \n",
    "sns.set(style=\"white\", rc={\"lines.linewidth\": 3})\n",
    "sns.barplot(x=['Kfold 1','Kfold 2','Kfold 3','Kfold 4','Kfold 5'],y=\"Scores\",data=scores)\n",
    "plt.show()\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_ada = ada.predict_proba(X_test)\n",
    "prob_ada = prob_ada[:,1]\n",
    "\n",
    "auc_ada = roc_auc_score(y_test,prob_ada)\n",
    "#print('AUC: %.2f'%auc_DT)\n",
    "fpr_ada, tpr_ada, thresholds_ada = roc_curve(y_test, prob_ada) \n",
    "\n",
    "plt.plot(fpr_ada, tpr_ada, color='blue', label='ada') \n",
    "plt.plot([0, 1], [0, 1], color='green', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. XGboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb1=XGBClassifier(learning_rate =0.1, n_estimators=1000, max_depth=8, min_child_weight=6, gamma=0.1, subsample=0.9,\n",
    "                     colsample_bytree=0.95,reg_alpha=2, objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27)\n",
    "xgb1.fit(X_train,y_train)\n",
    "y_pred = xgb1.predict(X_test)\n",
    "xgb1.score(X_test, y_test)\n",
    "\n",
    "confusion_majority=confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Mjority classifier Confusion Matrix\\n', confusion_majority)\n",
    "\n",
    "print('**********************')\n",
    "print('Mjority TN= ', confusion_majority[0][0])\n",
    "print('Mjority FP=',  confusion_majority[0][1])\n",
    "print('Mjority FN= ', confusion_majority[1][0])\n",
    "print('Mjority TP= ', confusion_majority[1][1])\n",
    "print('**********************')\n",
    "\n",
    "print('Precision= {:.2f}'.format(precision_score(y_test, y_pred)))\n",
    "print('Recall= {:.2f}'. format(recall_score(y_test, y_pred)))\n",
    "print('F1= {:.2f}'. format(f1_score(y_test, y_pred)))\n",
    "print('Accuracy= {:.2f}'. format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb1=XGBClassifier(learning_rate =0.1, n_estimators=1000, max_depth=8, min_child_weight=6, gamma=0.1, subsample=0.9,\n",
    "                     colsample_bytree=0.95,reg_alpha=2, objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27)\n",
    "\n",
    "kf = KFold(n_splits=5,shuffle=True)\n",
    "kf.split(X_train)\n",
    "\n",
    "accuracy_model = []\n",
    "i=0\n",
    "for train_index,test_index in kf.split(X_train):\n",
    "    \n",
    "    Xtrain, Xtest = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    ytrain, ytest = y_train[train_index], y_train[test_index]\n",
    "    xgb1.fit(Xtrain,ytrain)\n",
    "    accuracy_model.append(accuracy_score(ytest, xgb1.predict(Xtest), normalize=True)*100)\n",
    "    #print([i] \"of kfold\" + n_splits + accuracy_model[i])\n",
    "    print('\\n{} of kfold {}' .format(i+1,kf.n_splits))\n",
    "    print(accuracy_model[i])\n",
    "    i += 1\n",
    "\n",
    "    \n",
    "scores = pd.DataFrame(accuracy_model,columns=['Scores'])\n",
    " \n",
    "sns.set(style=\"white\", rc={\"lines.linewidth\": 3})\n",
    "sns.barplot(x=['Kfold 1','Kfold 2','Kfold 3','Kfold 4','Kfold 5'],y=\"Scores\",data=scores)\n",
    "plt.show()\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_xgb1 = xgb1.predict_proba(X_test)\n",
    "prob_xgb1 = prob_xgb1[:,1]\n",
    "\n",
    "auc_xgb1 = roc_auc_score(y_test,prob_xgb1)\n",
    "#print('AUC: %.2f'%auc_DT)\n",
    "fpr_xgb1, tpr_xgb1, thresholds_xgb1 = roc_curve(y_test, prob_xgb1) \n",
    "\n",
    "plt.plot(fpr_xgb1, tpr_xgb1, color='blue', label='xgb') \n",
    "plt.plot([0, 1], [0, 1], color='green', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier(criterion='entropy',max_depth=12)\n",
    "DT=  DT.fit(X_train,y_train)\n",
    "y_pred= DT.predict(X_test)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(DT.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(DT.score(X_test, y_test)))\n",
    "\n",
    "confusion_majority=confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Mjority classifier Confusion Matrix\\n', confusion_majority)\n",
    "\n",
    "print('**********************')\n",
    "print('Mjority TN= ', confusion_majority[0][0])\n",
    "print('Mjority FP=',  confusion_majority[0][1])\n",
    "print('Mjority FN= ', confusion_majority[1][0])\n",
    "print('Mjority TP= ', confusion_majority[1][1])\n",
    "print('**********************')\n",
    "\n",
    "print('Precision= {:.2f}'.format(precision_score(y_test, y_pred)))\n",
    "print('Recall= {:.2f}'. format(recall_score(y_test, y_pred)))\n",
    "print('F1= {:.2f}'. format(f1_score(y_test, y_pred)))\n",
    "print('Accuracy= {:.2f}'. format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier(criterion='entropy',max_depth=12)\n",
    "\n",
    "kf = KFold(n_splits=5,shuffle=True)\n",
    "kf.split(X_train)\n",
    "\n",
    "accuracy_model = []\n",
    "i=0\n",
    "for train_index,test_index in kf.split(X_train):\n",
    "    \n",
    "    Xtrain, Xtest = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    ytrain, ytest = y_train[train_index], y_train[test_index]\n",
    "    DT.fit(Xtrain,ytrain)\n",
    "    accuracy_model.append(accuracy_score(ytest, DT.predict(Xtest), normalize=True)*100)\n",
    "    #print([i] \"of kfold\" + n_splits + accuracy_model[i])\n",
    "    print('\\n{} of kfold {}' .format(i+1,kf.n_splits))\n",
    "    print(accuracy_model[i])\n",
    "    i += 1\n",
    "\n",
    "    \n",
    "scores = pd.DataFrame(accuracy_model,columns=['Scores'])\n",
    " \n",
    "sns.set(style=\"white\", rc={\"lines.linewidth\": 3})\n",
    "sns.barplot(x=['Kfold 1','Kfold 2','Kfold 3','Kfold 4','Kfold 5'],y=\"Scores\",data=scores)\n",
    "plt.show()\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_DT = DT.predict_proba(X_test)\n",
    "prob_DT = prob_DT[:,1]\n",
    "\n",
    "auc_DT = roc_auc_score(y_test,prob_DT)\n",
    "#print('AUC: %.2f'%auc_DT)\n",
    "fpr_DT, tpr_DT, thresholds_DT = roc_curve(y_test, prob_DT) \n",
    "\n",
    "plt.plot(fpr_DT, tpr_DT, color='blue', label='DT') \n",
    "plt.plot([0, 1], [0, 1], color='green', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert = X.iloc[[2345]].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(knn.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(knn.score(X_test, y_test)))\n",
    "#knn.score(X_test,y_test)\n",
    "\n",
    "confusion_majority=confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Mjority classifier Confusion Matrix\\n', confusion_majority)\n",
    "\n",
    "print('**********************')\n",
    "print('Mjority TN= ', confusion_majority[0][0])\n",
    "print('Mjority FP=',  confusion_majority[0][1])\n",
    "print('Mjority FN= ', confusion_majority[1][0])\n",
    "print('Mjority TP= ', confusion_majority[1][1])\n",
    "print('**********************')\n",
    "\n",
    "print('Precision= {:.2f}'.format(precision_score(y_test, y_pred)))\n",
    "print('Recall= {:.2f}'. format(recall_score(y_test, y_pred)))\n",
    "print('F1= {:.2f}'. format(f1_score(y_test, y_pred)))\n",
    "print('Accuracy= {:.2f}'. format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_knn = knn.predict_proba(X_test)\n",
    "prob_knn = prob_knn[:,1]\n",
    "\n",
    "auc_knn = roc_auc_score(y_test,prob_knn)\n",
    "#print('AUC: %.2f'%auc_DT)\n",
    "fpr_knn, tpr_knn, thresholds_knn = roc_curve(y_test, prob_knn) \n",
    "\n",
    "plt.plot(fpr_knn, tpr_knn, color='blue', label='DT') \n",
    "plt.plot([0, 1], [0, 1], color='green', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = range(1,20)\n",
    "scores = []\n",
    "\n",
    "# your codes here...\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k, weights='uniform')\n",
    "    knn.fit(X_train,y_train)\n",
    "    scores.append(knn.score(X_test,y_test))\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Accuracy by n_neigbors')\n",
    "plt.scatter(k_range, scores)\n",
    "plt.xticks([0,5,10,15,20]);\n",
    "plt.plot(k_range, scores, color='green', linestyle='dashed', linewidth=1, markersize=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr_DT, tpr_DT, color='blue', label='DT')\n",
    "plt.plot(fpr_knn, tpr_knn, color='red', label='KNN')\n",
    "plt.plot(fpr_forest, tpr_forest, color='yellow', label='RF')\n",
    "plt.plot(fpr_xgb1, tpr_xgb1, color='black', label='xgb1')\n",
    "plt.plot(fpr_ada, tpr_ada, color='darkmagenta', label='ada')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='green', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Association Rule mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['Bin_Loan_Amount'] = pd.cut(df3['Loan_Amount'], bins=[0,200000,400000,600000,800000])\n",
    "df3['Bin_Monthly_Salary'] = pd.cut(df3['Monthly_Salary'], bins=[0,4000,8000,12000,16000])\n",
    "df3['Bin_Total_Income_for_Join_Application'] = pd.cut(df3['Total_Income_for_Join_Application'], bins=[6000,10000,14000,18000,22000])\n",
    "df3['Bin_Total_Sum_of_Loan'] = pd.cut(df3['Total_Sum_of_Loan'], bins=[300000,600000,900000,1200000,1500000])\n",
    "df3['Bin_Loan_Tenure_Year'] = pd.cut(df3['Loan_Tenure_Year'], bins=[5,10,15,20,25])\n",
    "#df3['Bin_Years_to_Financial_Freedom'] = pd.cut(df3['Years_to_Financial_Freedom'], bins=[5,10,15,20])\n",
    "#df3['Bin_Credit_Card_Exceed_Months'] = pd.cut(df3['Credit_Card_Exceed_Months'], bins=[0,2,4,6,8])\n",
    "\n",
    "df3['Bin_Loan_Amount']=df3['Bin_Loan_Amount'].astype('str')\n",
    "df3['Bin_Total_Sum_of_Loan']=df3['Bin_Total_Sum_of_Loan'].astype('str')\n",
    "df3['Bin_Monthly_Salary']=df3['Bin_Monthly_Salary'].astype('str')\n",
    "df3['Bin_Total_Income_for_Join_Application']=df3['Bin_Total_Income_for_Join_Application'].astype('str')\n",
    "#df3['Bin_Credit_Card_Exceed_Months']=df3['Bin_Credit_Card_Exceed_Months'].astype('str')\n",
    "df3['Bin_Loan_Tenure_Year']=df3['Bin_Loan_Tenure_Year'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['Bin_Loan_Amount']=df3['Bin_Loan_Amount'].replace('(0, 200000]','Loan_Amount(0, 200000]')\n",
    "df3['Bin_Loan_Amount']=df3['Bin_Loan_Amount'].replace('(200000, 400000]','Loan_Amount(200000, 400000]')\n",
    "df3['Bin_Loan_Amount']=df3['Bin_Loan_Amount'].replace('(400000, 600000]','Loan_Amount(400000, 600000]')\n",
    "df3['Bin_Loan_Amount']=df3['Bin_Loan_Amount'].replace('(600000, 800000]','Loan_Amount(600000, 800000]')\n",
    "\n",
    "df3['Bin_Monthly_Salary']=df3['Bin_Monthly_Salary'].replace('(0, 4000]','Monthly_Salary(0, 4000]')\n",
    "df3['Bin_Monthly_Salary']=df3['Bin_Monthly_Salary'].replace('(4000, 8000]','Monthly_Salary(4000, 8000]')\n",
    "df3['Bin_Monthly_Salary']=df3['Bin_Monthly_Salary'].replace('(8000, 12000]','Monthly_Salary(8000, 12000]')\n",
    "df3['Bin_Monthly_Salary']=df3['Bin_Monthly_Salary'].replace('(12000, 16000]','Monthly_Salary(12000, 16000]')\n",
    "\n",
    "df3['Bin_Total_Sum_of_Loan']=df3['Bin_Total_Sum_of_Loan'].replace('(300000, 600000]','Total_Sum_of_Loan(300000, 600000]')\n",
    "df3['Bin_Total_Sum_of_Loan']=df3['Bin_Total_Sum_of_Loan'].replace('(600000, 900000]','Total_Sum_of_Loan(600000, 900000]')\n",
    "df3['Bin_Total_Sum_of_Loan']=df3['Bin_Total_Sum_of_Loan'].replace('(900000, 1200000]','Total_Sum_of_Loan(900000, 1200000]')\n",
    "df3['Bin_Total_Sum_of_Loan']=df3['Bin_Total_Sum_of_Loan'].replace('(1200000, 1500000]','Total_Sum_of_Loan(1200000, 1500000]')\n",
    "\n",
    "df3['Bin_Total_Income_for_Join_Application']=df3['Bin_Total_Income_for_Join_Application'].replace('(6000, 10000]','Total_Income_for_Join_Application(6000, 9000]')\n",
    "df3['Bin_Total_Income_for_Join_Application']=df3['Bin_Total_Income_for_Join_Application'].replace('(10000, 14000]','Total_Income_for_Join_Application(9000, 12000]')\n",
    "df3['Bin_Total_Income_for_Join_Application']=df3['Bin_Total_Income_for_Join_Application'].replace('(14000, 18000]','Total_Income_for_Join_Application(12000, 15000]')\n",
    "df3['Bin_Total_Income_for_Join_Application']=df3['Bin_Total_Income_for_Join_Application'].replace('(18000, 22000]','Total_Income_for_Join_Application(15000, 18000]')\n",
    "\n",
    "df3['Bin_Loan_Tenure_Year']=df3['Bin_Loan_Tenure_Year'].replace('(5, 10]','Loan_Tenure_Year(5, 10]')\n",
    "df3['Bin_Loan_Tenure_Year']=df3['Bin_Loan_Tenure_Year'].replace('(15, 20]','Loan_Tenure_Year(15, 20]')\n",
    "df3['Bin_Loan_Tenure_Year']=df3['Bin_Loan_Tenure_Year'].replace('(20, 25]','Loan_Tenure_Year(20, 25]')\n",
    "df3['Bin_Loan_Tenure_Year']=df3['Bin_Loan_Tenure_Year'].replace('(10, 15]','Loan_Tenure_Year(10, 15]')\n",
    "\n",
    "\n",
    "#df3['Bin_Credit_Card_Exceed_Months']=df3['Bin_Credit_Card_Exceed_Months'].replace('(0, 2]','Credit_Card_Exceed_Months(0, 2]')\n",
    "#df3['Bin_Credit_Card_Exceed_Months']=df3['Bin_Credit_Card_Exceed_Months'].replace('(2, 4]','Credit_Card_Exceed_Months(2, 4]')\n",
    "#df3['Bin_Credit_Card_Exceed_Months']=df3['Bin_Credit_Card_Exceed_Months'].replace('(4, 6]','Credit_Card_Exceed_Months(4, 6]')\n",
    "#df3['Bin_Credit_Card_Exceed_Months']=df3['Bin_Credit_Card_Exceed_Months'].replace('(6, 8]','Credit_Card_Exceed_Months(6, 8]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=df3[['Employment_Type','Credit_Card_types','Bin_Total_Income_for_Join_Application','Bin_Total_Sum_of_Loan','Bin_Monthly_Salary','Bin_Loan_Amount','Property_Type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "banks = []\n",
    "for i in range(0, 2350):\n",
    "    banks.append([str(df3.values[i,j]) for j in range(0, 7)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "association_rules = apriori(banks,min_support=0.0040,min_confidence=0.45,min_lift=3,min_length=2)\n",
    "association_results = list(association_rules)\n",
    "association_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the len\n",
    "len(association_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt =0\n",
    "\n",
    "for item in association_results:\n",
    "    cnt += 1\n",
    "    # first index of the inner list\n",
    "    # Contains base item and add item\n",
    "    pair = item[0] \n",
    "    items = [x for x in pair]\n",
    "    print(\"(Rule \" + str(cnt) + \") \" + items[0] + \" -> \" + items[1])\n",
    "\n",
    "    #second index of the inner list\n",
    "    print(\"Support: \" + str(round(item[1],3)))\n",
    "\n",
    "    #third index of the list located at 0th\n",
    "    #of the third index of the inner list\n",
    "\n",
    "    print(\"Confidence: \" + str(round(item[2][0][2],4)))\n",
    "    print(\"Lift: \" + str(round(item[2][0][3],4)))\n",
    "    print(\"=====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = df1.copy() \n",
    "\n",
    "dfc = df2.copy()\n",
    "Xc = dfc.drop(\"Decision\",axis=1)\n",
    "yc = dfc[\"Decision\"]\n",
    "\n",
    "Xc = pd.get_dummies(Xc, drop_first=True)\n",
    "Xc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=3,random_state=12)\n",
    "km.fit(Xc)\n",
    "km.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc2 = df2.copy()\n",
    "dfc2 = dfc2.drop(\"Decision\",axis=1)\n",
    "dfc2[\"Label\"] = km.labels_\n",
    "dfc2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,5))\n",
    "plt.subplot(121)\n",
    "sns.scatterplot(dft['Monthly_Salary'],dft['Loan_Amount'],hue=dft['Decision'])\n",
    "plt.subplot(122) \n",
    "sns.scatterplot(dfc2['Monthly_Salary'],dfc2['Loan_Amount'],hue=dfc2['Label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,5))\n",
    "plt.subplot(121)\n",
    "sns.scatterplot(dft['Total_Income_for_Join_Application'],dft['Loan_Amount'],hue=dft['Decision'])\n",
    "plt.subplot(122) \n",
    "sns.scatterplot(dfc2['Total_Income_for_Join_Application'],dfc2['Loan_Amount'],hue=dfc2['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,5))\n",
    "plt.subplot(121)\n",
    "sns.scatterplot(dft['Total_Income_for_Join_Application'],dft['Total_Sum_of_Loan'],hue=dft['Decision'])\n",
    "plt.subplot(122) \n",
    "sns.scatterplot(dfc2['Total_Income_for_Join_Application'],dfc2['Total_Sum_of_Loan'],hue=dfc2['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,5))\n",
    "plt.subplot(121)\n",
    "sns.scatterplot(dft['Monthly_Salary'],dft['Total_Sum_of_Loan'],hue=dft['Decision'])\n",
    "plt.subplot(122)\n",
    "sns.scatterplot(dfc2['Monthly_Salary'],dfc2['Total_Sum_of_Loan'],hue=dfc2['Label'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Silhouette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.cluster import silhouette_visualizer\n",
    "print(\"Silhouette Score(n=2)= \", silhouette_score(dfc2, dfc2['Label']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_visualizer(KMeans(3, random_state=12), dfc2, colors=\"yellowbrick\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distortions\n",
    "distortions = []\n",
    "\n",
    "for i in range(1,11):\n",
    "    km = KMeans(\n",
    "        n_clusters = i, init= \"random\",\n",
    "        n_init=10,max_iter=300,\n",
    "        tol=1e-04, random_state=0\n",
    "    )\n",
    "    km.fit(Xc)\n",
    "    distortions.append(km.inertia_)\n",
    "#plot\n",
    "\n",
    "plt.plot(range(1,11),distortions,marker='o')\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"Distortion\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
